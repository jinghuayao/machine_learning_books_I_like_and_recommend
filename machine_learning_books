1. Hang Li, Statistical Machine Learning, Tsinghua University Press, 2012.

This book covers the typical shallow models (mainly supervised models; does not cover neural networks) 
and is written in a very clear fashion. In the first chapter, the author overviews the field of machine 
learning, while in the last chapter summarizes the covered machine learning algorithms. In between, the 
author presents one main algorithm in each chapter by first laying down the theory and then giving a 
concise example. I feel this is a carefully written book after reading through it several times.

2. Zhihua Zhou, Machine Learning, Tsinghua University Press, 2016.

This book contains 16 chapters with useful appendices. It covers both supervised and unsupervised algorithms,
and also touches reinforcement learning. In terms of coverage, this book is of wide spectrum. Due to the wide coverage,
some topics are not fully expanded. This book is very popular in China. After reading through, you will find that it is
really nice to be used as an introductory book in the field of machine learning. Personally, I like the stories at the 
end of each chapter. It is safe to say that the author made great effort in adding some of his thoughts in writing the book.


3. Tieyan Liu, etal, Distributed Machine Learning: Theories, Algorithms, and Systems, China Machine Press, 2018.

This book presents distributed machine learning framework. It is very useful to the practice of training very large model with
big data set. It also contains two chapters on optimization algorithms. This book is written in a high level, in particular,
conveying the main results without proofs. This is both good and not good in representing materials. It is good if you have solid
background and use it for a high level review or summary of the topic. It is not good if you use it as the main text because 
knowing the statements of the main results and theorems are far from understanding them, not mentioning grasping the connections 
among them. If you are well trained in a techinial field such as mathematics and also have solid background in machine learning 
(theory and training), there is a lot of fun in reading this book. The authors of the book are experts and practitioners in the topic.

4. Aurélien Géron, Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to 
Build Intelligent Systems, O'Reilly Media; 1 edition (April 9, 2017).

This is a very well-written book. When I first read through this book, it was just released and was the 1st edition. 
It consists of two big parts: shallow models, neural networks. It is of wide spectrum in terms of coverage. It can help 
you get started in engineer side and also can help you gain a solid understanding of the theoretical side: the author 
includes all the main references explicitly. Geron is a machine learning expert with both genuine engineer experience
and very good machematical understanding, which is my feeling after reading through the book. Personally, I had read through 
this book a number of times, and each time I could gain something new. Now this book has its second edition incoporating Keras.

5. Francois Chollet, Deep Learning with Python Manning Publications, Dec 2017, 1st Edition

This is a very book for gaining both engineer understanding and practice in machine learning, especially in deep learning. 
The author is also the author of Keras, a very friendly-to-use API for implementing deep neural networks. 
The representation is concise yet sufficiently detailed, and full of ideas and sound personal understanding about deep learning models. 
I especially like the comments of the authors about the role of gates in LSTM cell in reality. This is a book which deserves your 
reading through a number of times as I confirmed after doing so.


Probability and Statistics Foundations.

1. Patrick Billingsley, Probability and Measure, 3rd edition, Wiley, 1995.

This book is a masterpiece, classic. It contains a huge amount of information. When I was a graduate student, I studied this book for
two semesters with a very rigorous research professor and did a large portion of the excercises at the end of each section. 
These excercises also contain huge amount of materials.  I feel that the materials in some sections together are sufficient to be used 
as a real analysis textbook. I refer to this book frequently when using statistics and doing fundamental and applied research. 
From a mathematical point of view, some of the theorems or properties proved in some of the CVPR, ICML, NeurlPS papers are just 
special cases or rediscover of some of the results in this book. If you do a systematic study of this book, it is guaranteed that 
your analysis technical power will be greatly enhanced.

2. David Freedman, Statistics, W. W. Norton & Company, 4th Edition, 2007.

This book is now in its 4th edition. The exposition of the book is lucid. It focuses the core ideas of concepts and methods 
with light mathematical formulas. My feeling is that I can gain a very good statistical feeling of the fundamental concepts and
methods.

3. Christopher Bishop, Pattern Recognition and Machine Learning, Springer, 1st edition, 2006.

This book is a well known text in the field, and the author is a well known expert in the field. It may be more proper to put it 
in the machine learning class for my list. However, I used it slightly differently from other books. This book takes a Bayesian 
point of view and contains abundant information. I like the second chapter very much and use it as a reference for 
probability distributions. Though I had read through the book and find the book has theoretical depth, wide coverage and 
is very good for reference, there are two small points which do not aligh to my taste very well: first, from time to time, 
I feel it is wordy. When I read chapter 1, I felt that I need take a long breath in order to finish some of the whole sentences; 
second, the author presented the material in a whole sections without using thoerems, properties and remarks. Though explicit structure 
format is not necessary, putting all the formulas and conclusions together without a clear hierarchy in a section is not a best way 
for presenting heavy materials.

